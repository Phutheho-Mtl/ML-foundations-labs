{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c066849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ddb4a4",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Below we upload all the data from our bank notes collected in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33612e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.50813</td>\n",
       "      <td>0.47799</td>\n",
       "      <td>-1.980400</td>\n",
       "      <td>0.57714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-3.84830</td>\n",
       "      <td>-12.80470</td>\n",
       "      <td>15.682400</td>\n",
       "      <td>-1.28100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.34810</td>\n",
       "      <td>-0.38696</td>\n",
       "      <td>-0.478410</td>\n",
       "      <td>0.62627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.78690</td>\n",
       "      <td>9.56630</td>\n",
       "      <td>-3.786700</td>\n",
       "      <td>-7.50340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.85610</td>\n",
       "      <td>6.91760</td>\n",
       "      <td>-0.793720</td>\n",
       "      <td>0.48403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-2.41150</td>\n",
       "      <td>-9.13590</td>\n",
       "      <td>9.344400</td>\n",
       "      <td>-0.65259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.47368</td>\n",
       "      <td>3.36050</td>\n",
       "      <td>-4.506400</td>\n",
       "      <td>-4.04310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.40400</td>\n",
       "      <td>8.72610</td>\n",
       "      <td>-2.991500</td>\n",
       "      <td>-0.57242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.28015</td>\n",
       "      <td>3.07290</td>\n",
       "      <td>-3.385700</td>\n",
       "      <td>-2.91550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.39012</td>\n",
       "      <td>-0.14279</td>\n",
       "      <td>-0.031994</td>\n",
       "      <td>0.35084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    variance  skewness   curtosis  entropy  class\n",
       "83   0.50813   0.47799  -1.980400  0.57714      1\n",
       "53  -3.84830 -12.80470  15.682400 -1.28100      1\n",
       "70  -0.34810  -0.38696  -0.478410  0.62627      1\n",
       "45  -0.78690   9.56630  -3.786700 -7.50340      0\n",
       "44   2.85610   6.91760  -0.793720  0.48403      0\n",
       "..       ...       ...        ...      ...    ...\n",
       "60  -2.41150  -9.13590   9.344400 -0.65259      1\n",
       "71   0.47368   3.36050  -4.506400 -4.04310      1\n",
       "14   3.40400   8.72610  -2.991500 -0.57242      0\n",
       "92  -0.28015   3.07290  -3.385700 -2.91550      1\n",
       "51   0.39012  -0.14279  -0.031994  0.35084      1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df=pd.read_csv(\"banknote_authentication.csv\",sep=\";\")\n",
    "bank_df=bank_df.sample(frac=1, random_state=42)  # Randomise\n",
    "bank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe6f6a",
   "metadata": {},
   "source": [
    "# Test-train data split\n",
    "We split it into 20-80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d912b60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "# TRAIN #\n",
      "#########\n",
      "first ten rows of s2_train_features = \n",
      " [[  0.50813   0.47799  -1.9804    0.57714]\n",
      " [ -3.8483  -12.8047   15.6824   -1.281  ]\n",
      " [ -0.3481   -0.38696  -0.47841   0.62627]\n",
      " [ -0.7869    9.5663   -3.7867   -7.5034 ]\n",
      " [  2.8561    6.9176   -0.79372   0.48403]\n",
      " [  3.4805    9.7008   -3.7541   -3.4379 ]\n",
      " [  3.9362   10.1622   -3.8235   -4.0172 ]\n",
      " [ -2.7338    0.45523   2.4391    0.21766]\n",
      " [  1.2247    8.7779   -2.2135   -0.80647]\n",
      " [  3.6216    8.6661   -2.8073   -0.44699]]\n",
      "\n",
      "first ten elements of s2_train_labels = \n",
      " [1 1 1 0 0 0 0 1 0 0]\n",
      "\n",
      "########\n",
      "# TEST #\n",
      "########\n",
      "first ten rows of s2_test_features = \n",
      " [[-0.36506  2.8928  -3.6461  -3.0603 ]\n",
      " [ 1.6408   4.2503  -4.9023  -2.6621 ]\n",
      " [ 3.6289   0.81322  1.6277   0.77627]\n",
      " [ 4.8906  -3.3584   3.4202   1.0905 ]\n",
      " [ 4.5459   8.1674  -2.4586  -1.4621 ]\n",
      " [-1.6677  -7.1535   7.8929   0.96765]\n",
      " [ 0.3292  -4.4552   4.5718  -0.9888 ]\n",
      " [ 3.866   -2.6383   1.9242   0.10645]\n",
      " [ 0.93584  8.8855  -1.6831  -1.6599 ]\n",
      " [-3.2238   2.7935   0.32274 -0.86078]]\n",
      "\n",
      "first ten elements of s2_test_labels = \n",
      " [1 1 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "split_index = int(bank_df.shape[0] * 0.8)\n",
    "print(\"#########\")\n",
    "print(\"# TRAIN #\")\n",
    "print(\"#########\")\n",
    "s2_train_features=bank_df.iloc[:split_index, :-1].to_numpy()\n",
    "s2_train_labels=bank_df.iloc[:split_index, -1].to_numpy()\n",
    "\n",
    "print(f\"first ten rows of s2_train_features = \\n {s2_train_features[:10]}\")\n",
    "print(f\"\\nfirst ten elements of s2_train_labels = \\n {s2_train_labels[:10]}\")\n",
    "\n",
    "print(\"\\n########\")\n",
    "print(\"# TEST #\")\n",
    "print(\"########\")\n",
    "s2_test_features=bank_df.iloc[split_index:, :-1].to_numpy()\n",
    "s2_test_labels=bank_df.iloc[split_index:, -1].to_numpy()\n",
    "\n",
    "print(f\"first ten rows of s2_test_features = \\n {s2_test_features[:10]}\")\n",
    "print(f\"\\nfirst ten elements of s2_test_labels = \\n {s2_test_labels[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5e7cd",
   "metadata": {},
   "source": [
    "# Prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0800808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.525, 0.475])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_priors=np.zeros(2)\n",
    "class_zero_count=0\n",
    "class_one_count=0\n",
    "for label in s2_train_labels:\n",
    "    if (label==0):\n",
    "        class_zero_count+=1\n",
    "    else:\n",
    "        class_one_count+=1\n",
    "s2_priors[0]=class_zero_count/ len(s2_train_labels)\n",
    "s2_priors[1]=class_one_count/ len(s2_train_labels)\n",
    "\n",
    "s2_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938f10d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Class-Conditional Gaussian Parameters (Manual Implementation)\n",
    "\n",
    "For each feature \\(x_i\\) and class \\(c\\), the mean \\(\\mu_{x_i,c}\\) and variance \\(\\sigma^2_{x_i,c}\\) are computed **explicitly using the analytical formulas** from *textbook formulas*, and **not** using any built-in NumPy statistics functions.\n",
    "\n",
    "The formulas used are:\n",
    "\n",
    "\\[\n",
    "\\mu_{x_i,c} = \\frac{1}{N_c} \\sum_{n=1}^{N_c} x_i^{(n)}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\sigma^2_{x_i,c} = \\frac{1}{N_c} \\sum_{n=1}^{N_c} \\left(x_i^{(n)} - \\mu_{x_i,c}\\right)^2\n",
    "\\]\n",
    "\n",
    "These equations are implemented directly using loops and basic arithmetic.\n",
    "\n",
    "**Note:** Functions such as `np.mean`, `np.var`, `np.std`, or any other statistical library routines were deliberately not used in this implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36a20207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.11768924,  5.20368119,  0.34544714, -1.74017955],\n",
       "       [-1.82843   , -0.68951058,  1.54479248, -1.21049189]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_cc_mean=np.zeros((2, 4))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        sum_feature_class_zero=0\n",
    "        sum_feature_class_one=0\n",
    "        for k in range(len(s2_train_labels)):\n",
    "            if s2_train_labels[k]==0:\n",
    "                sum_feature_class_zero+=s2_train_features[k][j]\n",
    "            else:\n",
    "                sum_feature_class_one+=s2_train_features[k][j]\n",
    "        if i==0:\n",
    "            s2_cc_mean[i][j]=sum_feature_class_zero/class_zero_count\n",
    "        else:\n",
    "            s2_cc_mean[i][j]=sum_feature_class_one/class_one_count\n",
    "\n",
    "s2_cc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d01199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.02932591,  26.38644283,  15.08515814,   5.05878121],\n",
       "       [112.39413608, 140.53866419, 162.80956804, 167.65640758]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_cc_var=np.zeros((2,4))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        sum_feature_class_zero=0\n",
    "        sum_feature_class_zero=0\n",
    "        for k in range(len(s2_train_labels)):\n",
    "            if s2_train_labels[k]==0:\n",
    "                sum_feature_class_zero+=(s2_train_features[k][j] - s2_cc_mean[i][j])**2\n",
    "            else:\n",
    "                sum_feature_class_one+=(s2_train_features[k][j] - s2_cc_mean[i][j])**2\n",
    "        if i==0:\n",
    "            s2_cc_var[i][j]=sum_feature_class_zero/class_zero_count\n",
    "        else:\n",
    "            s2_cc_var[i][j]=sum_feature_class_one/class_one_count\n",
    "s2_cc_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe20ec0",
   "metadata": {},
   "source": [
    "**b)** Implemented below is  the function `s2_class_conditional_fn` which will compute $P(x_i | c)$. This function takes in the feature, class (class_label), mean and variance (var).\n",
    "- `feature`: $x_i$\n",
    "- `class_label`: $c$\n",
    "- `mean`: mean ($\\mu_{x_i, c}$) of associated gaussian distribution for $(x_i, c)$\n",
    "- `var`: variance ($\\sigma^2_{x_i, c}$) of associated gaussian distribution for $(x_i, c)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab22e35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x_0=0.50813|c=0) = 0.14410453742602167\n",
      "P(x_0=0.50813|c=1) = 0.051141559173017714\n"
     ]
    }
   ],
   "source": [
    "def s2_class_conditional_fn(feature, class_label, mean, var):\n",
    "    cond_prob=...  # i.e. P(x_i | c)\n",
    "    cond_prob=(1/np.sqrt(2*np.pi*var))*np.exp(-(1/2)*(feature - mean)**2/var)\n",
    "    return cond_prob\n",
    "\n",
    "tmp_feature=s2_train_features[0, 0]\n",
    "# tmp_class = 0\n",
    "print(f\"P(x_0={tmp_feature}|c={0}) = {s2_class_conditional_fn(tmp_feature, 0, s2_cc_mean[0, 0], s2_cc_var[0, 0])}\")\n",
    "print(f\"P(x_0={tmp_feature}|c={1}) = {s2_class_conditional_fn(tmp_feature, 1, s2_cc_mean[0, 1], s2_cc_var[0, 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585b18f",
   "metadata": {},
   "source": [
    "# Posterior Probability\n",
    "Below is the function `s2_calc_posterior` that calculates the posterior probability of a given class based off given data. I.e. it should compute $P(c|x)$.\n",
    "- `feature`: $x$\n",
    "- `class_label`: $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7655fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c=0 | x=[-0.36506  2.8928  -3.6461  -3.0603 ]) = 5.484612613732366e-22\n",
      "P(c=1 | x=[-0.36506  2.8928  -3.6461  -3.0603 ]) = 7.508286941437842e-25\n"
     ]
    }
   ],
   "source": [
    "def s2_calc_posterior(class_label, feature):\n",
    "    post_prob=s2_priors[class_label]\n",
    "\n",
    "    for f in feature:\n",
    "        for i in range(4):\n",
    "            post_prob*=s2_class_conditional_fn(f, class_label, s2_cc_mean[class_label][i], s2_cc_var[class_label][i])\n",
    "    denominator=0\n",
    "\n",
    "    for i in range(2):\n",
    "        for f in feature:\n",
    "            for j in range(4):\n",
    "                denominator+=s2_class_conditional_fn(f, i, s2_cc_mean[i][j], s2_cc_var[i][j])*s2_priors[i]\n",
    "    post_prob/= denominator\n",
    "\n",
    "    return post_prob\n",
    "\n",
    "\n",
    "print(f\"P(c=0 | x={s2_test_features[0]}) = {s2_calc_posterior(0, s2_test_features[0])}\")\n",
    "print(f\"P(c=1 | x={s2_test_features[0]}) = {s2_calc_posterior(1, s2_test_features[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936e963",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b0c18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred class for x=[-0.36506  2.8928  -3.6461  -3.0603 ] = 0\n"
     ]
    }
   ],
   "source": [
    "def s2_infer_class(feature):\n",
    "    c = ...\n",
    "    class_zero_prob=s2_calc_posterior(0, feature)\n",
    "    class_one_prob=s2_calc_posterior(1, feature)\n",
    "    if class_zero_prob>class_one_prob:\n",
    "        c=0\n",
    "    else:\n",
    "        c=1\n",
    "    return c\n",
    "\n",
    "print(f\"Inferred class for x={s2_test_features[0]} = {s2_infer_class(s2_test_features[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b65e1",
   "metadata": {},
   "source": [
    "# Confusion matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f62844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "s2_confusion_matrix=np.zeros((2, 2))\n",
    "actual_class=s2_test_labels\n",
    "predicted_class=[]\n",
    "for feature in s2_test_features:\n",
    "    predicted_class.append(s2_infer_class(feature))\n",
    "\n",
    "s2_confusion_matrix=confusion_matrix(actual_class, predicted_class)\n",
    "\n",
    "print(s2_confusion_matrix)\n",
    "\n",
    "\n",
    "#COMPUTE ACCURACY\n",
    "s2_acc = ...\n",
    "s2_acc = (s2_confusion_matrix[0][0] + s2_confusion_matrix[1][1])\n",
    "denominator = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        denominator += s2_confusion_matrix[i][j]\n",
    "s2_acc = s2_acc/denominator\n",
    "\n",
    "s2_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
