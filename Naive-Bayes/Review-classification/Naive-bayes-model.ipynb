{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341aa9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels : \n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "Reviews : \n",
      " ['the food is lovely', 'this is a great restaurant', 'i really enjoyed my food', 'i enjoyed the experience at the restaurant', 'we had a lovely meal', 'my food tasted great', 'the food was lovely and the service was not bad', 'the service was great', 'what a lovely restaurant', 'the food the service and the restaurant was great', 'this restaurant is lovely', 'the service is terrible', 'the food tasted awful', 'this is a bad restaurant  ', 'the food was really bad', 'the service and the food was terrible', 'we had a terrible experience', 'avoid this restaurant', 'avoid the food', 'the meal was terrible', 'the service was bad']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "\n",
    "\n",
    "##LOAD DATA\n",
    "labels=[]\n",
    "reviews=[]\n",
    "\n",
    "with open(\"simple-food-reviews.txt\",\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        line=line.replace(\"\\n\",\"\")\n",
    "        words=line.split(\" \")\n",
    "        label=int(words[0])\n",
    "        review=\" \".join(words[1:])\n",
    "        labels.append(label)\n",
    "        reviews.append(review)\n",
    "##HERE WE PRINT THE LABELS AND REVIEWS TO CHECK IF IT GOT LOADED WELL\n",
    "if not(len(labels)==len(reviews)):\n",
    "    print(\"DID NOT LOAD LABELS AND REVIEWS PROPERLY\")\n",
    "else:\n",
    "    print(\"Labels : \\n\",labels)\n",
    "    print(\"Reviews : \\n\",reviews)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6868a",
   "metadata": {},
   "source": [
    "# Process Features\n",
    "\n",
    "Below I create a bag of words from the dataset in reviews so that we have a list of unique words contained in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c31d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'food', 'is', 'lovely', 'this', 'a', 'great', 'restaurant', 'i', 'really', 'enjoyed', 'my', 'experience', 'at', 'we', 'had', 'meal', 'tasted', 'was', 'and', 'service', 'not', 'bad', 'what', 'terrible', 'awful', 'avoid']\n",
      "Your review 1 features: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Correct review 1 features: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "create_features correct for first review: review_1_features = correct_features\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "bag_of_words=[]\n",
    "seen_words=set()\n",
    "\n",
    "for review in reviews:\n",
    "    words=re.findall(r'\\b\\w+\\b', review.lower())  #Here I tokenise the words\n",
    "    for word in words:\n",
    "        if word not in seen_words:\n",
    "            bag_of_words.append(word)#Only add words have not been seen\n",
    "            seen_words.add(word)\n",
    "\n",
    "##verify visually if all words are unique\n",
    "print(bag_of_words)\n",
    "\n",
    "\n",
    "##CREATE FEATURES\n",
    "\n",
    "def create_features(review):\n",
    "    review_features=[0]*len(bag_of_words)\n",
    "    review_words=re.findall(r'\\b\\w+\\b',review.lower())##Split the review into an array of words then check them against bag of words\n",
    "    for i,word in enumerate(bag_of_words):\n",
    "        if(word in review_words):\n",
    "            review_features[i]=1\n",
    "    #return a python list of 1s and 0s\n",
    "    return review_features\n",
    "\n",
    "\n",
    "##BELOW WE TEST IF CREATE FEATURES FOR THE 1ST REVIEW ACTUALLY WORKED PROPERLY\n",
    "review_1_features = create_features(reviews[0])\n",
    "print(f\"Your review 1 features: {review_1_features}\")\n",
    "\n",
    "correct_features = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "print(f\"Correct review 1 features: {correct_features}\\n\")\n",
    "\n",
    "if review_1_features == correct_features:\n",
    "    print(f\"create_features correct for first review: review_1_features = correct_features\")\n",
    "else:\n",
    "    print(f\"create_features incorrect for first review: review_1_features != correct_features\")\n",
    "\n",
    "\n",
    "##PROCESS ALL FEATURES\n",
    "\n",
    "review_features=[create_features(review) for review in reviews]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876320c",
   "metadata": {},
   "source": [
    "# Train and Test Data Split\n",
    "\n",
    "Below we split our data into training and testing data.We do not create a validation split since we do not change any hyperparameters in our model.We do this manually for convenience though on a proffesional level this is done randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21765c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "# TRAIN SPLIT #\n",
      "###############\n",
      "\n",
      "train_reviews:\n",
      " ['the food is lovely', 'this is a great restaurant', 'i really enjoyed my food', 'i enjoyed the experience at the restaurant', 'we had a lovely meal', 'my food tasted great', 'the food was lovely and the service was not bad', 'the service was great', 'what a lovely restaurant', 'the food the service and the restaurant was great', 'the service is terrible', 'the food tasted awful', 'this is a bad restaurant  ', 'the food was really bad', 'the service and the food was terrible', 'we had a terrible experience', 'avoid this restaurant', 'avoid the food', 'the meal was terrible']\n",
      "train_features:\n",
      " [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
      "train_labels\n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "\n",
      "###############\n",
      "# TEST SPLIT #\n",
      "###############\n",
      "\n",
      "test_reviews:\n",
      " ['this restaurant is lovely', 'the service was bad']\n",
      "test_features:\n",
      " [[0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]]\n",
      "test_labels\n",
      " [1, -1]\n"
     ]
    }
   ],
   "source": [
    "##WE SPLIT 90% FOR TRAINING \n",
    "print(\"###############\")\n",
    "print(\"# TRAIN SPLIT #\")\n",
    "print(\"###############\\n\")\n",
    "\n",
    "train_reviews=reviews[:10]+reviews[11:-1]\n",
    "train_features=review_features[:10]+review_features[11:-1]\n",
    "train_labels=labels[:10]+labels[11:-1]\n",
    "\n",
    "print(\"train_reviews:\\n\", train_reviews)\n",
    "print(\"train_features:\\n\", train_features)\n",
    "print(\"train_labels\\n\", train_labels)\n",
    "\n",
    "print(\"\\n###############\")\n",
    "print(\"# TEST SPLIT #\")\n",
    "print(\"###############\\n\")\n",
    "#WE SPLIT 10% FOR TESTING\n",
    "test_reviews = [reviews[10], reviews[-1]]\n",
    "test_features = [review_features[10], review_features[-1]]\n",
    "test_labels = [labels[10], labels[-1]]\n",
    "\n",
    "\n",
    "\n",
    "print(\"test_reviews:\\n\", test_reviews)\n",
    "print(\"test_features:\\n\", test_features)\n",
    "print(\"test_labels\\n\", test_labels)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1b112",
   "metadata": {},
   "source": [
    "# Naive Bayes Computations\n",
    "## Below we compute all components of our Naive Bayes model before combining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2826ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_pos = 0.5263157894736842\n",
      "p_neg = 0.47368421052631576\n",
      "number of positive reviews 10\n",
      "number of negative reviews in the training data 9\n",
      "\n",
      "class_conditionals =\n",
      " [[0.5        0.5        0.2        0.4        0.1        0.3\n",
      "  0.4        0.4        0.2        0.1        0.2        0.2\n",
      "  0.1        0.1        0.1        0.1        0.1        0.1\n",
      "  0.3        0.2        0.3        0.1        0.1        0.1\n",
      "  0.         0.         0.        ]\n",
      " [0.66666667 0.44444444 0.22222222 0.         0.22222222 0.22222222\n",
      "  0.         0.22222222 0.         0.11111111 0.         0.\n",
      "  0.11111111 0.         0.11111111 0.11111111 0.11111111 0.11111111\n",
      "  0.33333333 0.11111111 0.22222222 0.         0.22222222 0.\n",
      "  0.44444444 0.11111111 0.22222222]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#COMPUTE PRIOR PROBABILITIES OF THE LABELS \"negative(-1)\" and \"positive(-1)\"\n",
    "number_of_negative_reviews=0\n",
    "number_of_positive_reviews=0\n",
    "for number in train_labels:\n",
    "    if number==-1:\n",
    "        number_of_negative_reviews=number_of_negative_reviews+1\n",
    "    else:\n",
    "        number_of_positive_reviews=number_of_positive_reviews+1\n",
    "p_pos=number_of_positive_reviews/len(train_labels)\n",
    "p_neg=number_of_negative_reviews/len(train_labels)\n",
    "print(f\"p_pos = {p_pos}\")\n",
    "print(f\"p_neg = {p_neg}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#COMPUTE THE CLASS CONDITIONAL MODELS FOR EACH FEATURE AND CLASS\n",
    "class_conditionals = np.zeros((2, len(bag_of_words)))\n",
    "print(f\"number of positive reviews {number_of_positive_reviews}\")\n",
    "print(f\"number of negative reviews in the training data {number_of_negative_reviews}\")\n",
    "\n",
    "#for every word in bag of words,go to the negative reviews and count how many times does it appear and after that go to the positive reviews \n",
    "for i in range(len(bag_of_words)):\n",
    "    word=bag_of_words[i].lower()\n",
    "    positive_count=0\n",
    "    negative_count=0\n",
    "    for k in range(len(train_reviews)):  #check if the review is negative or positive \n",
    "        review = re.findall(r'\\b\\w+\\b', train_reviews[k].lower()) \n",
    "        if (word in review):\n",
    "            if (train_labels[k]==1):\n",
    "                #The word is in a positive review\n",
    "                positive_count=positive_count+1\n",
    "            else:\n",
    "                negative_count=negative_count+1\n",
    "    #set the word's conditional probability\n",
    "    class_conditionals[0][i]=positive_count/number_of_positive_reviews\n",
    "    class_conditionals[1][i]=negative_count/number_of_negative_reviews\n",
    "\n",
    "\n",
    "print(f\"\\nclass_conditionals =\\n {class_conditionals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de0d4f",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Next we will infer the associated label for the review \"the service was bad\" in our test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c657f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer Review:  this restaurant is lovely\n",
      "Infer Features:  [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "\n",
    "infer_review = test_reviews[0]\n",
    "infer_features = test_features[0]\n",
    "\n",
    "print(\"Infer Review: \", infer_review)\n",
    "print(\"Infer Features: \", infer_features)\n",
    "\n",
    "\n",
    "##WE COMPUTE THE CLASS CONDITIONALS MODELS FOR INFER FEATURES\n",
    "##infer features for the positive class\n",
    "class_cond_pos =1\n",
    "for number in infer_features:\n",
    "    if number==1:\n",
    "        class_cond_pos=class_cond_pos*(class_conditionals[0][i])\n",
    "    else:\n",
    "        class_cond_pos=class_cond_pos*(1-class_conditionals[0][i])\n",
    "\n",
    "##Infer features for the negative class\n",
    "class_cond_neg = 1.0\n",
    "for number in infer_features:\n",
    "    if number==1:\n",
    "        class_cond_pos=float(class_cond_pos*(class_conditionals[1][i]))\n",
    "    else:\n",
    "        class_cond_pos=float(class_cond_pos*(1-class_conditionals[1][i]))\n",
    "\n",
    "\n",
    "\n",
    "p_infer_features = float(p_pos*class_cond_pos+p_neg*class_cond_neg)#P(X=infer_features)\n",
    "p_cond_pos =float(p_pos*class_cond_pos/p_infer_features)#P(C=positive|infer_features)\n",
    "p_cond_neg =1-p_cond_pos     #P(C=negative|infer_features)\n",
    "\n",
    "#print(p_cond_neg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729bce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label for the review 'this restaurant is lovely' is 1.0\n"
     ]
    }
   ],
   "source": [
    "###PREDICT THE MOST LIKELY LABEL FOR THIS REVIEW\n",
    "\n",
    "pred_label =max(p_cond_pos,p_cond_neg)\n",
    "\n",
    "print(f\"The predicted label for the review '{infer_review}' is {pred_label}\")\n",
    "# print(pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626afef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
